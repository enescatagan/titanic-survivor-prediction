{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before EDA let's reroll a bit:\n",
    "\n",
    "In `1_load_data__understand.ipynb` notebook in `\\notebooks\\testing` we;\n",
    "* load data\n",
    "* Set index to `PassengerId` feature\n",
    "* Get some kind of understanding from bird view on dataset\n",
    "  * We find Null values and Decided actions such\n",
    "    * `Age` attribute has *177* NaN\n",
    "      * Fill up with a regression model (not decided yet)\n",
    "    * `Cabin` attribute has *687* NaN\n",
    "      * First we will extract `CabinType` then delete `Cabin` feature\n",
    "      * Second We will fill up with a classification model (not decided yet)\n",
    "    * `Embarked` attribute has *2* NaN\n",
    "      * Simple Classification will enough for filling\n",
    "* Detecting Outliers;\n",
    "  * We will search for `Age` and `Fare` attributes for outliers\n",
    "* We will create some new features;\n",
    "  * From `Age` --> Create `AgeBucket` --> Delete `Age` If good for model\n",
    "  * From `Name` --> Create `Title` and `FamilySize` --> Delete `Name`\n",
    "  * From `SibSp` and `Parch` --> Create `RelativesOnBoard` --> Delete `SibSp` and `Parch` If good for model\n",
    "  * From `Ticket` --> Create `DoesHaveSameTicket` --> Delete `Ticket`\n",
    "  * From `Cabin` --> Create `CabinType` --> Delete `Cabin`\n",
    "* We found out skewness\n",
    "  * `Fare` feature has positive skewness; we will handle with **log transformation**\n",
    "  * `Age` feature has possible skewness; bu will ignore it because we won't use this feature directly\n",
    "* Encoding;\n",
    "  * `Sex`, `Embarked`, `DoesHaveSameTicket`(We will create), `Title`(We will create) and `CabinType`(We will create) will use **OneHotEncode**\n",
    "  * `Pclass` will use **OrdinalEncode**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Create data preprocessing guideline:\n",
    "\n",
    "1. Fill up NaN values\n",
    "2. Search for Outliers\n",
    "3. Create Features\n",
    "4. Handle Skewness if has it\n",
    "5. Encode\n",
    "\n",
    "| Feature | Steps |\n",
    "| ------- | :--: |\n",
    "| `Pclass` | 5 |\n",
    "| `Name` | 3 |\n",
    "| `Sex` | 5 |\n",
    "| `Age` | 1, 2, 3, 4 (if not deleted) |\n",
    "| `SibSp` | 3 |\n",
    "| `Parch` | 3 |\n",
    "| `Ticket` | 3 |\n",
    "| `Fare` | 2, 4 |\n",
    "| `Cabin` | 3 |\n",
    "| `Embarked` | 1, 5 |\n",
    "\n",
    "**Feature Creation And Deletions**\n",
    "| Feature From | New Feature | New Feature Steps | Deletion of Old one? |\n",
    "| ------------ | ----------- | :---------------: | :-------------: |\n",
    "| `Name` | `Title` | 5, 2, 5 | Yes |\n",
    "| `Name` | `FamilySize` | | Yes |\n",
    "| `Age` | `AgeBucket` | | Decide by score |\n",
    "| `SibSp` and `Parch` | `RelativesOnBoard` | | Decide by score |\n",
    "| `Ticket` | `DoesHaveSameTicket` | 5 | Yes |\n",
    "| `Cabin` | `CabinType` | 5 | Yes |\n",
    "\n",
    "* `Name`, `Ticket` and `Cabin` features after creating new features will **DELETED**.\n",
    "* `Age`, `SibSp` and `Parch` features after creating new features, we will see impact on a model then decided for deleted or not.\n",
    "\n",
    "**Note:**\n",
    "I did not include scaling for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These inferences are after first glance from dataset; can add to it or reduce it. I want to write now before EDA, because I will much more deep info after EDA, then I can review my first view and determine my actions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.width\",500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and split the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "train_data = pd.read_csv('../../data/train.csv')\n",
    "test_data = pd.read_csv('../../data/test.csv')\n",
    "\n",
    "# Set index\n",
    "train_data = train_data.set_index('PassengerId')\n",
    "test_data = test_data.set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Let's split data according of their data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "Object Columns: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "train_data_num = train_data.select_dtypes(include=[np.number])\n",
    "train_data_obj = train_data.select_dtypes(include=\"object\")\n",
    "\n",
    "print(f\"Numerical Columns: {list(train_data_num.columns)}\")\n",
    "print(f\"Object Columns: {list(train_data_obj.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see unique counts of these data types; and then we will determine more specific data types for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      2\n",
      "Pclass        3\n",
      "Age          88\n",
      "SibSp         7\n",
      "Parch         7\n",
      "Fare        248\n",
      "dtype: int64\n",
      "\n",
      "Name        891\n",
      "Sex           2\n",
      "Ticket      681\n",
      "Cabin       147\n",
      "Embarked      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data[train_data_num.columns].nunique(), end=\"\\n\\n\")\n",
    "print(train_data[train_data_obj.columns].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For Numerical as we can see `Pclass`, `SibSp`, `Parch` has not many unique values, and `Age` and `Fare` a lot of unique values, and lastly `Survived` attribute is target.\n",
    "* For Object: As we can see `Sex` and `Embarked` are least uniques that appropriate for setting as **categorical attributes**. `Ticket`, `Cabin` and `Name` are more like a text data that uniqueness count is high; we can set these as **cardinal attributes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass  SibSp  Parch\n",
      "PassengerId                      \n",
      "1                 3      1      0\n",
      "2                 1      1      0\n",
      "3                 3      0      0\n",
      "\n",
      "              Age     Fare\n",
      "PassengerId               \n",
      "1            22.0   7.2500\n",
      "2            38.0  71.2833\n",
      "3            26.0   7.9250\n",
      "\n",
      "                Sex Embarked\n",
      "PassengerId                 \n",
      "1              male        S\n",
      "2            female        C\n",
      "3            female        S\n",
      "\n",
      "                       Ticket Cabin                                               Name\n",
      "PassengerId                                                                           \n",
      "1                   A/5 21171   NaN                            Braund, Mr. Owen Harris\n",
      "2                    PC 17599   C85  Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
      "3            STON/O2. 3101282   NaN                             Heikkinen, Miss. Laina\n",
      "\n",
      "PassengerId\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data_discrete_num = train_data[['Pclass', 'SibSp', 'Parch']]\n",
    "train_data_continuous_num = train_data[['Age', 'Fare']]\n",
    "\n",
    "train_data_cat = train_data[['Sex', 'Embarked']]\n",
    "train_data_car = train_data[['Ticket', 'Cabin', 'Name']]\n",
    "\n",
    "train_data_target = train_data['Survived']\n",
    "\n",
    "# Let's see first 3 data\n",
    "print(train_data_discrete_num[:3], end=\"\\n\\n\")\n",
    "print(train_data_continuous_num[:3], end=\"\\n\\n\")\n",
    "print(train_data_cat[:3], end=\"\\n\\n\")\n",
    "print(train_data_car[:3], end=\"\\n\\n\")\n",
    "print(train_data_target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** these assignments only for EDA, we will redo for ML.\n",
    "\n",
    "Let's recap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All numerical Columns: \t['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "All Object Columns: \t['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\n",
      "Discrete Numerical Columns: \t['Pclass', 'SibSp', 'Parch']\n",
      "Continues Numerical Columns: \t['Age', 'Fare']\n",
      "\n",
      "Categorical Columns: \t['Sex', 'Embarked']\n",
      "Cardinal Columns: \t['Ticket', 'Cabin', 'Name']\n"
     ]
    }
   ],
   "source": [
    "print(f\"All numerical Columns: \\t{list(train_data_num.columns)}\")\n",
    "print(f\"All Object Columns: \\t{list(train_data_obj.columns)}\\n\")\n",
    "print(f\"Discrete Numerical Columns: \\t{list(train_data_discrete_num.columns)}\")\n",
    "print(f\"Continues Numerical Columns: \\t{list(train_data_continuous_num.columns)}\\n\")\n",
    "print(f\"Categorical Columns: \\t{list(train_data_cat.columns)}\")\n",
    "print(f\"Cardinal Columns: \\t{list(train_data_car.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
